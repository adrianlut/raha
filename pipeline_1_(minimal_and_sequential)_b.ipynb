{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Data Cleaning Pipeline with Raha and Baran (Minimal and Sequential)\n",
    "We build an end-to-end data cleaning pipeline with our configuration-free error detection and correction systems, Raha and Baran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import IPython.display\n",
    "from pandas import DataFrame, Series\n",
    "import pickle\n",
    "import raha\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection with Raha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instantiating the Detection Class\n",
    "We first instantiate the `Detection` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1 = raha.Detection()\n",
    "\n",
    "# How many tuples would you label?\n",
    "app_1.LABELING_BUDGET = 20\n",
    "\n",
    "# Would you like to see the logs?\n",
    "app_1.VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiating the Dataset\n",
    "We next load and instantiate the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  tuple_id src           flight sched_dep_time act_dep_time sched_arr_time  \\\n0        1  aa  AA-3859-IAH-ORD      7:10 a.m.    7:16 a.m.      9:40 a.m.   \n1        2  aa  AA-1733-ORD-PHX      7:45 p.m.    7:58 p.m.     10:30 p.m.   \n2        3  aa  AA-1640-MIA-MCO      6:30 p.m.                   7:25 p.m.   \n3        4  aa   AA-518-MIA-JFK      6:40 a.m.    6:54 a.m.      9:25 a.m.   \n4        5  aa  AA-3756-ORD-SLC     12:15 p.m.   12:41 p.m.      2:45 p.m.   \n\n  act_arr_time  \n0    9:32 a.m.  \n1               \n2               \n3    9:28 a.m.  \n4    2:50 p.m.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tuple_id</th>\n      <th>src</th>\n      <th>flight</th>\n      <th>sched_dep_time</th>\n      <th>act_dep_time</th>\n      <th>sched_arr_time</th>\n      <th>act_arr_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>aa</td>\n      <td>AA-3859-IAH-ORD</td>\n      <td>7:10 a.m.</td>\n      <td>7:16 a.m.</td>\n      <td>9:40 a.m.</td>\n      <td>9:32 a.m.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>aa</td>\n      <td>AA-1733-ORD-PHX</td>\n      <td>7:45 p.m.</td>\n      <td>7:58 p.m.</td>\n      <td>10:30 p.m.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>aa</td>\n      <td>AA-1640-MIA-MCO</td>\n      <td>6:30 p.m.</td>\n      <td></td>\n      <td>7:25 p.m.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>aa</td>\n      <td>AA-518-MIA-JFK</td>\n      <td>6:40 a.m.</td>\n      <td>6:54 a.m.</td>\n      <td>9:25 a.m.</td>\n      <td>9:28 a.m.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>aa</td>\n      <td>AA-3756-ORD-SLC</td>\n      <td>12:15 p.m.</td>\n      <td>12:41 p.m.</td>\n      <td>2:45 p.m.</td>\n      <td>2:50 p.m.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dictionary = {\n",
    "    \"name\": \"flights\",\n",
    "    \"path\": \"datasets/flights/dirty.csv\",\n",
    "    \"clean_path\": \"datasets/flights/clean.csv\"\n",
    "}\n",
    "d = app_1.initialize_dataset(dataset_dictionary)\n",
    "d.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Running Error Detection Strategies\n",
    "Raha runs (all or the promising) error detection strategies on the dataset. This step could take a while because all the strategies should be run on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 strategy profiles are collected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I just load strategies' results as they have already been run on the dataset!\n"
     ]
    }
   ],
   "source": [
    "app_1.run_strategies(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generating Features\n",
    "Raha then generates a feature vector for each data cell based on the output of error detection strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 Features are generated for column 0.\n",
      "65 Features are generated for column 1.\n",
      "62 Features are generated for column 2.\n",
      "65 Features are generated for column 3.\n",
      "71 Features are generated for column 4.\n",
      "65 Features are generated for column 5.\n",
      "86 Features are generated for column 6.\n"
     ]
    }
   ],
   "source": [
    "app_1.generate_features(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Building Clusters\n",
    "Raha next builds a hierarchical clustering model for our clustering-based sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A hierarchical clustering model is built for column 0.\n",
      "A hierarchical clustering model is built for column 1.\n",
      "A hierarchical clustering model is built for column 2.\n",
      "A hierarchical clustering model is built for column 3.\n",
      "A hierarchical clustering model is built for column 4.\n",
      "A hierarchical clustering model is built for column 5.\n",
      "A hierarchical clustering model is built for column 6.\n"
     ]
    }
   ],
   "source": [
    "app_1.build_clusters(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Interactive Tuple Sampling and Labeling\n",
    "Raha then iteratively samples a tuple. We should label data cells of each sampled tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple 39 is sampled.\n",
      "Tuple 39 is labeled.\n",
      "Tuple 1939 is sampled.\n",
      "Tuple 1939 is labeled.\n",
      "Tuple 222 is sampled.\n",
      "Tuple 222 is labeled.\n",
      "Tuple 2016 is sampled.\n",
      "Tuple 2016 is labeled.\n",
      "Tuple 943 is sampled.\n",
      "Tuple 943 is labeled.\n",
      "Tuple 1619 is sampled.\n",
      "Tuple 1619 is labeled.\n",
      "Tuple 262 is sampled.\n",
      "Tuple 262 is labeled.\n",
      "Tuple 1035 is sampled.\n",
      "Tuple 1035 is labeled.\n",
      "Tuple 688 is sampled.\n",
      "Tuple 688 is labeled.\n",
      "Tuple 572 is sampled.\n",
      "Tuple 572 is labeled.\n",
      "Tuple 1409 is sampled.\n",
      "Tuple 1409 is labeled.\n",
      "Tuple 1099 is sampled.\n",
      "Tuple 1099 is labeled.\n",
      "Tuple 708 is sampled.\n",
      "Tuple 708 is labeled.\n",
      "Tuple 1042 is sampled.\n",
      "Tuple 1042 is labeled.\n",
      "Tuple 1498 is sampled.\n",
      "Tuple 1498 is labeled.\n",
      "Tuple 1685 is sampled.\n",
      "Tuple 1685 is labeled.\n",
      "Tuple 2152 is sampled.\n",
      "Tuple 2152 is labeled.\n",
      "Tuple 241 is sampled.\n",
      "Tuple 241 is labeled.\n",
      "Tuple 1729 is sampled.\n",
      "Tuple 1729 is labeled.\n",
      "Tuple 290 is sampled.\n",
      "Tuple 290 is labeled.\n"
     ]
    }
   ],
   "source": [
    "while len(d.labeled_tuples) < app_1.LABELING_BUDGET:\n",
    "    app_1.sample_tuple(d)\n",
    "    if d.has_ground_truth:\n",
    "        app_1.label_with_ground_truth(d)\n",
    "    else:\n",
    "        print(\"Label the dirty cells in the following sampled tuple.\")\n",
    "        sampled_tuple = pandas.DataFrame(data=[d.dataframe.iloc[d.sampled_tuple, :]], columns=d.dataframe.columns)\n",
    "        IPython.display.display(sampled_tuple)\n",
    "        for j in range(d.dataframe.shape[1]):\n",
    "            cell = (d.sampled_tuple, j)\n",
    "            value = d.dataframe.iloc[cell]\n",
    "            correction = input(\"What is the correction for value '{}'? Type in the same value if it is not erronous.\\n\".format(value))\n",
    "            user_label = 1 if value != correction else 0\n",
    "            d.labeled_cells[cell] = [user_label, correction]\n",
    "        d.labeled_tuples[d.sampled_tuple] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Propagating User Labels\n",
    "Raha then propagates each user label through its cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of labeled data cells increased from 140 to 12307.\n"
     ]
    }
   ],
   "source": [
    "app_1.propagate_labels(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Predicting Labels of Data Cells\n",
    "Raha then trains and applies one classifier per data column to predict the label of the rest of data cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classifier is trained and applied on column 0.\n",
      "A classifier is trained and applied on column 1.\n",
      "A classifier is trained and applied on column 2.\n",
      "A classifier is trained and applied on column 3.\n",
      "A classifier is trained and applied on column 4.\n",
      "A classifier is trained and applied on column 5.\n",
      "A classifier is trained and applied on column 6.\n"
     ]
    }
   ],
   "source": [
    "app_1.predict_labels(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Storing Results\n",
    "Raha can also store the error detection results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are stored in datasets/flights/raha-baran-results-flights/error-detection/detection.dataset.\n"
     ]
    }
   ],
   "source": [
    "app_1.store_results(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Evaluating the Error Detection Task\n",
    "We can finally evaluate our error detection task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raha's performance on flights:\n",
      "Precision = 0.70\n",
      "Recall = 0.82\n",
      "F1 = 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/source/MA/raha/raha/dataset.py:123: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if correction_dictionary[cell] == actual_errors[cell]:\n"
     ]
    }
   ],
   "source": [
    "p, r, f = d.get_data_cleaning_evaluation(d.detected_cells)[:3]\n",
    "print(\"Raha's performance on {}:\\nPrecision = {:.2f}\\nRecall = {:.2f}\\nF1 = {:.2f}\".format(d.name, p, r, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Correction with Baran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instantiating the Correction Class\n",
    "We first instantiate the `Correction` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_2 = raha.Correction()\n",
    "\n",
    "# How many tuples would you label?\n",
    "app_2.LABELING_BUDGET = 20\n",
    "\n",
    "# Would you like to see the logs?\n",
    "app_2.VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initializing the Dataset Object\n",
    "We next initialize the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  tuple_id src           flight sched_dep_time act_dep_time sched_arr_time  \\\n0        1  aa  AA-3859-IAH-ORD      7:10 a.m.    7:16 a.m.      9:40 a.m.   \n1        2  aa  AA-1733-ORD-PHX      7:45 p.m.    7:58 p.m.     10:30 p.m.   \n2        3  aa  AA-1640-MIA-MCO      6:30 p.m.                   7:25 p.m.   \n3        4  aa   AA-518-MIA-JFK      6:40 a.m.    6:54 a.m.      9:25 a.m.   \n4        5  aa  AA-3756-ORD-SLC     12:15 p.m.   12:41 p.m.      2:45 p.m.   \n\n  act_arr_time  \n0    9:32 a.m.  \n1               \n2               \n3    9:28 a.m.  \n4    2:50 p.m.  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tuple_id</th>\n      <th>src</th>\n      <th>flight</th>\n      <th>sched_dep_time</th>\n      <th>act_dep_time</th>\n      <th>sched_arr_time</th>\n      <th>act_arr_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>aa</td>\n      <td>AA-3859-IAH-ORD</td>\n      <td>7:10 a.m.</td>\n      <td>7:16 a.m.</td>\n      <td>9:40 a.m.</td>\n      <td>9:32 a.m.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>aa</td>\n      <td>AA-1733-ORD-PHX</td>\n      <td>7:45 p.m.</td>\n      <td>7:58 p.m.</td>\n      <td>10:30 p.m.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>aa</td>\n      <td>AA-1640-MIA-MCO</td>\n      <td>6:30 p.m.</td>\n      <td></td>\n      <td>7:25 p.m.</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>aa</td>\n      <td>AA-518-MIA-JFK</td>\n      <td>6:40 a.m.</td>\n      <td>6:54 a.m.</td>\n      <td>9:25 a.m.</td>\n      <td>9:28 a.m.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>aa</td>\n      <td>AA-3756-ORD-SLC</td>\n      <td>12:15 p.m.</td>\n      <td>12:41 p.m.</td>\n      <td>2:45 p.m.</td>\n      <td>2:50 p.m.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = app_2.initialize_dataset(d)\n",
    "d.dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initializing the Error Corrector Models\n",
    "Baran initializes the error corrector models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error corrector models are initialized.\n"
     ]
    }
   ],
   "source": [
    "app_2.initialize_models(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interactive Tuple Sampling, Labeling, Model updating, Feature Generation, and Correction Prediction\n",
    "Baran then iteratively samples a tuple. We should label data cells of each sampled tuple. It then udpates the models accordingly and generates a feature vector for each pair of a data error and a correction candidate. Finally, it trains and applies a classifier to each data column to predict the final correction of each data error. Since we already labeled tuples for Raha, we use the same labeled tuples and do not label new tuples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error corrector models are updated with new labeled tuple 39.\n",
      "363336 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 396\n",
      "    Column 4: 85\n",
      "    Column 5: 1080\n",
      "    Column 6: 2580\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 107 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 884 Mean confidence: 0.9546409508258391\n",
      "    Column 6: 348 Mean confidence: 0.9999928314673372\n",
      "Corrections applied in this step:\n",
      "    Column 3: 510\n",
      "    Column 4: 107\n",
      "    Column 5: 884\n",
      "    Column 6: 331\n",
      "32% (1879 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1939.\n",
      "363336 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 396\n",
      "    Column 4: 85\n",
      "    Column 5: 1080\n",
      "    Column 6: 2580\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 45 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 884 Mean confidence: 0.9546409508258391\n",
      "    Column 6: 348 Mean confidence: 0.9999928314673372\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "32% (1879 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 222.\n",
      "373700 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 406\n",
      "    Column 4: 127\n",
      "    Column 5: 1082\n",
      "    Column 6: 2594\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 124 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 883 Mean confidence: 0.9927172202287365\n",
      "    Column 6: 348 Mean confidence: 0.9999928314673372\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 17\n",
      "    Column 5: 844\n",
      "    Column 6: 0\n",
      "33% (1915 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 2016.\n",
      "381878 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 412\n",
      "    Column 4: 158\n",
      "    Column 5: 1089\n",
      "    Column 6: 2608\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 145 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 883 Mean confidence: 0.9927018525192169\n",
      "    Column 6: 348 Mean confidence: 0.9999928314673372\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 21\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "33% (1936 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 943.\n",
      "385006 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 412\n",
      "    Column 4: 177\n",
      "    Column 5: 1089\n",
      "    Column 6: 2622\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 170 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 883 Mean confidence: 0.9927018525192169\n",
      "    Column 6: 400 Mean confidence: 0.9644587284814061\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 25\n",
      "    Column 5: 0\n",
      "    Column 6: 50\n",
      "35% (2011 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1619.\n",
      "387318 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 418\n",
      "    Column 4: 181\n",
      "    Column 5: 1094\n",
      "    Column 6: 2626\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 170 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 883 Mean confidence: 0.9927018525190981\n",
      "    Column 6: 383 Mean confidence: 0.9585648760762082\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "35% (2011 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 262.\n",
      "392728 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 430\n",
      "    Column 4: 202\n",
      "    Column 5: 1099\n",
      "    Column 6: 2630\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 195 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 883 Mean confidence: 0.99270185251898\n",
      "    Column 6: 383 Mean confidence: 0.9563388332586237\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 25\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "35% (2036 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1035.\n",
      "395768 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 430\n",
      "    Column 4: 219\n",
      "    Column 5: 1100\n",
      "    Column 6: 2644\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 217 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 883 Mean confidence: 0.9926829991139808\n",
      "    Column 6: 348 Mean confidence: 0.9047193956067033\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 22\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "35% (2058 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 688.\n",
      "403733 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 436\n",
      "    Column 4: 249\n",
      "    Column 5: 1115\n",
      "    Column 6: 2654\n",
      "Corrections identified in this step:\n",
      "    Column 3: 510 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 237 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 793 Mean confidence: 0.9999960294586251\n",
      "    Column 6: 348 Mean confidence: 0.9051355532575592\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 20\n",
      "    Column 5: 793\n",
      "    Column 6: 0\n",
      "36% (2094 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 572.\n",
      "410597 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 448\n",
      "    Column 4: 273\n",
      "    Column 5: 1115\n",
      "    Column 6: 2659\n",
      "Corrections identified in this step:\n",
      "    Column 3: 533 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 260 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 818 Mean confidence: 0.9867013719521327\n",
      "    Column 6: 348 Mean confidence: 0.9051356900585421\n",
      "Corrections applied in this step:\n",
      "    Column 3: 23\n",
      "    Column 4: 23\n",
      "    Column 5: 256\n",
      "    Column 6: 0\n",
      "37% (2153 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1409.\n",
      "415322 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 462\n",
      "    Column 4: 295\n",
      "    Column 5: 1119\n",
      "    Column 6: 2664\n",
      "Corrections identified in this step:\n",
      "    Column 3: 558 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 285 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 943 Mean confidence: 0.9778793567373395\n",
      "    Column 6: 314 Mean confidence: 0.9988793586352568\n",
      "Corrections applied in this step:\n",
      "    Column 3: 25\n",
      "    Column 4: 25\n",
      "    Column 5: 256\n",
      "    Column 6: 185\n",
      "40% (2302 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1099.\n",
      "428770 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 477\n",
      "    Column 4: 339\n",
      "    Column 5: 1128\n",
      "    Column 6: 2687\n",
      "Corrections identified in this step:\n",
      "    Column 3: 577 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 304 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 793 Mean confidence: 0.9999959928687119\n",
      "    Column 6: 314 Mean confidence: 0.9989022175968127\n",
      "Corrections applied in this step:\n",
      "    Column 3: 19\n",
      "    Column 4: 19\n",
      "    Column 5: 0\n",
      "    Column 6: 41\n",
      "40% (2340 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 708.\n",
      "433228 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 477\n",
      "    Column 4: 353\n",
      "    Column 5: 1131\n",
      "    Column 6: 2694\n",
      "Corrections identified in this step:\n",
      "    Column 3: 577 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 304 Mean confidence: 0.9999999999999998\n",
      "    Column 5: 818 Mean confidence: 0.9863735106926595\n",
      "    Column 6: 175 Mean confidence: 0.9999945473632379\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 114\n",
      "40% (2340 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1042.\n",
      "433492 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 481\n",
      "    Column 4: 358\n",
      "    Column 5: 1135\n",
      "    Column 6: 2694\n",
      "Corrections identified in this step:\n",
      "    Column 3: 577 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 0 Mean confidence: nan\n",
      "    Column 5: 818 Mean confidence: 0.9862213844385059\n",
      "    Column 6: 175 Mean confidence: 0.9999945473632379\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "40% (2340 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1498.\n",
      "450005 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 496\n",
      "    Column 4: 413\n",
      "    Column 5: 1145\n",
      "    Column 6: 2727\n",
      "Corrections identified in this step:\n",
      "    Column 3: 0 Mean confidence: nan\n",
      "    Column 4: 0 Mean confidence: nan\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 208 Mean confidence: 0.9999945413257413\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 33\n",
      "41% (2365 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1685.\n",
      "461494 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 496\n",
      "    Column 4: 459\n",
      "    Column 5: 1156\n",
      "    Column 6: 2736\n",
      "Corrections identified in this step:\n",
      "    Column 3: 599 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 346 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 210 Mean confidence: 0.756518867234352\n",
      "Corrections applied in this step:\n",
      "    Column 3: 22\n",
      "    Column 4: 42\n",
      "    Column 5: 0\n",
      "    Column 6: 1\n",
      "42% (2430 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 2152.\n",
      "468543 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 511\n",
      "    Column 4: 480\n",
      "    Column 5: 1161\n",
      "    Column 6: 2752\n",
      "Corrections identified in this step:\n",
      "    Column 3: 624 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 371 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 227 Mean confidence: 0.944898663977369\n",
      "Corrections applied in this step:\n",
      "    Column 3: 25\n",
      "    Column 4: 25\n",
      "    Column 5: 0\n",
      "    Column 6: 19\n",
      "43% (2499 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 241.\n",
      "475645 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 514\n",
      "    Column 4: 510\n",
      "    Column 5: 1163\n",
      "    Column 6: 2758\n",
      "Corrections identified in this step:\n",
      "    Column 3: 624 Mean confidence: 0.9999999999999998\n",
      "    Column 4: 0 Mean confidence: nan\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 0 Mean confidence: nan\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "43% (2499 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 1729.\n",
      "475645 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 514\n",
      "    Column 4: 510\n",
      "    Column 5: 1163\n",
      "    Column 6: 2758\n",
      "Corrections identified in this step:\n",
      "    Column 3: 0 Mean confidence: nan\n",
      "    Column 4: 396 Mean confidence: 0.9999999999999999\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 0 Mean confidence: nan\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 25\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "43% (2524 / 5803) of data errors are corrected.\n",
      "The error corrector models are updated with new labeled tuple 290.\n",
      "482147 pairs of (a data error, a potential correction) are featurized.\n",
      "Prediction Method in this step:\n",
      "    Column 3: Train\n",
      "    Column 4: Train\n",
      "    Column 5: Train\n",
      "    Column 6: Train\n",
      "Train sizes in this step:\n",
      "    Column 3: 526\n",
      "    Column 4: 531\n",
      "    Column 5: 1173\n",
      "    Column 6: 2770\n",
      "Corrections identified in this step:\n",
      "    Column 3: 0 Mean confidence: nan\n",
      "    Column 4: 0 Mean confidence: nan\n",
      "    Column 5: 0 Mean confidence: nan\n",
      "    Column 6: 0 Mean confidence: nan\n",
      "Corrections applied in this step:\n",
      "    Column 3: 0\n",
      "    Column 4: 0\n",
      "    Column 5: 0\n",
      "    Column 6: 0\n",
      "43% (2524 / 5803) of data errors are corrected.\n"
     ]
    }
   ],
   "source": [
    "# while len(d.labeled_tuples) < app_2.LABELING_BUDGET:\n",
    "#     app_2.sample_tuple(d)\n",
    "#     if d.has_ground_truth:\n",
    "#         app_2.label_with_ground_truth(d)\n",
    "#     else:\n",
    "#         print(\"Label the dirty cells in the following sampled tuple.\")\n",
    "#         sampled_tuple = pandas.DataFrame(data=[d.dataframe.iloc[d.sampled_tuple, :]], columns=d.dataframe.columns)\n",
    "#         IPython.display.display(sampled_tuple)\n",
    "#         for j in range(d.dataframe.shape[1]):\n",
    "#             cell = (d.sampled_tuple, j)\n",
    "#             value = d.dataframe.iloc[cell]\n",
    "#             correction = input(\"What is the correction for value '{}'? Type in the same value if it is not erronous.\\n\".format(value))\n",
    "#             user_label = 1 if value != correction else 0\n",
    "#             d.labeled_cells[cell] = [user_label, correction]\n",
    "#         d.labeled_tuples[d.sampled_tuple] = 1\n",
    "#     app_2.update_models(d)\n",
    "#     app_2.generate_features(d)\n",
    "#     app_2.predict_corrections(d)\n",
    "\n",
    "#labeled_tuples_list = list(d.labeled_tuples.keys())\n",
    "#k = labeled_tuples_list[0]\n",
    "\n",
    "#si = d.labeled_tuples[k]\n",
    "#d.sampled_tuple = k\n",
    "#app_2.update_models(d)\n",
    "#app_2.generate_features(d)\n",
    "\n",
    "for si in d.labeled_tuples:\n",
    "    d.sampled_tuple = si\n",
    "    app_2.update_models(d)\n",
    "    app_2.generate_features(d)\n",
    "    app_2.predict_corrections(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#d.corrected_cells = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#app_2.predict_corrections(d)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Storing Results\n",
    "Baran can also store the error correction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results are stored in datasets/flights/raha-baran-results-flights/error-correction/correction.dataset.\n"
     ]
    }
   ],
   "source": [
    "app_2.store_results(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluating the Error Correction Task\n",
    "We can finally evaluate our error correction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baran's performance on flights:\n",
      "Precision = 0.82\n",
      "Recall = 0.42\n",
      "F1 = 0.56\n"
     ]
    }
   ],
   "source": [
    "p, r, f = d.get_data_cleaning_evaluation(d.corrected_cells)[-3:]\n",
    "print(\"Baran's performance on {}:\\nPrecision = {:.2f}\\nRecall = {:.2f}\\nF1 = {:.2f}\".format(d.name, p, r, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "actual_errors = d.get_actual_errors_dictionary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#d = pickle.load(open(\"datasets/flights/raha-baran-results-flights/error-correction/correction.dataset\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "16632"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.dataframe.shape[0] * d.dataframe.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "detected_cell_list = list(d.detected_cells.items())\n",
    "probabilities = [detection[1] for detection in detected_cell_list]\n",
    "is_correctly_detected = [cell[0] in actual_errors for cell in detected_cell_list]\n",
    "p_array = np.array(probabilities)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.000e+00, 0.000e+00, 1.300e+01, 0.000e+00, 0.000e+00, 0.000e+00,\n        0.000e+00, 6.000e+00, 5.000e+00, 1.200e+01, 0.000e+00, 1.000e+01,\n        1.000e+01, 9.000e+00, 3.300e+01, 4.000e+00, 2.800e+01, 1.200e+01,\n        6.500e+01, 5.596e+03]),\n array([0.5  , 0.525, 0.55 , 0.575, 0.6  , 0.625, 0.65 , 0.675, 0.7  ,\n        0.725, 0.75 , 0.775, 0.8  , 0.825, 0.85 , 0.875, 0.9  , 0.925,\n        0.95 , 0.975, 1.   ]),\n <a list of 20 Patch objects>)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_array[:,1], bins=np.linspace(0.5, 1.0, 21))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "p_df = DataFrame([list(detection[0]) + list(detection[1]) for detection in detected_cell_list], columns=[\"row\", \"column\", \"p_not\", \"p\"])\n",
    "p_df = p_df[[\"row\", \"column\", \"p\"]]\n",
    "p_df[\"correct\"] = is_correctly_detected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "correct\nFalse    [[AxesSubplot(0.125,0.125;0.775x0.755)]]\nTrue     [[AxesSubplot(0.125,0.125;0.775x0.755)]]\ndtype: object"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_df[[\"correct\",\"p\"]].groupby(\"correct\").hist(bins=np.linspace(0.5, 1.0, 21))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "undetected_cell_list = list(d.undetected_cells.items())\n",
    "probabilities = [detection[1] for detection in undetected_cell_list]\n",
    "is_correctly_detected = [cell[0] not in actual_errors for cell in undetected_cell_list]\n",
    "\n",
    "p_df_n = DataFrame([list(detection[0]) + list(detection[1]) for detection in undetected_cell_list], columns=[\"row\", \"column\", \"p_not\", \"p\"])\n",
    "p_df_n = p_df_n[[\"row\", \"column\", \"p\"]]\n",
    "p_df_n[\"correct\"] = is_correctly_detected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "correct\nFalse    [[AxesSubplot(0.125,0.125;0.775x0.755)]]\nTrue     [[AxesSubplot(0.125,0.125;0.775x0.755)]]\ndtype: object"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p_df_n[[\"correct\",\"p\"]].groupby(\"correct\").hist(bins=np.linspace(0.0, 0.5, 21))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "low_p = p_df[p_df[\"p\"] < 0.60]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "13"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_p.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "5803"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "low_p_dataframe = d.dataframe.loc[low_p[\"row\"].unique(),:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "4005"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(d.extended_labeled_cells.values())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "correction_features = []\n",
    "\n",
    "for cell in d.corrected_cells:\n",
    "    correction_features.append(list(cell) +\n",
    "                               [d.dataframe.iloc[cell]] +\n",
    "                               [d.corrected_cells[cell]] +\n",
    "                               [actual_errors[cell] if cell in actual_errors else d.dataframe.iloc[cell]] +\n",
    "                               list(d.pair_features[cell][d.corrected_cells[cell]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "correction_features_df = DataFrame(correction_features,\n",
    "                                   columns=[\"row\",\n",
    "                                            \"column\",\n",
    "                                            \"old_value\",\n",
    "                                            \"new_value\",\n",
    "                                            \"actual_value\",\n",
    "                                            *[f\"feature_value_{i}\" for i in range(8)],\n",
    "                                            *[f\"feature_vicinity_{i}\" for i in range(7)],\n",
    "                                            \"feature_domain\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "feature_value_0       0.000396\nfeature_value_1       0.000396\nfeature_value_2       0.005046\nfeature_value_3       0.005046\nfeature_vicinity_1    0.008810\nfeature_value_5       0.011136\nfeature_vicinity_0    0.018621\nfeature_domain        0.019134\nfeature_value_7       0.021031\nfeature_value_4       0.032224\nfeature_vicinity_4    0.042789\nfeature_value_6       0.057344\nfeature_vicinity_5    0.200561\nfeature_vicinity_3    0.220696\nfeature_vicinity_6    0.301334\nfeature_vicinity_2    0.877990\ndtype: float64"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_features_df.iloc[:,5:].mean().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "        feature_value_0  feature_value_1  feature_value_2  feature_value_3  \\\ncolumn                                                                       \n3              0.000000         0.000000         0.006485         0.006485   \n4              0.000000         0.000000         0.005990         0.005990   \n5              0.001063         0.001063         0.004642         0.004642   \n6              0.000000         0.000000         0.003332         0.003332   \n\n        feature_value_4  feature_value_5  feature_value_6  feature_value_7  \\\ncolumn                                                                       \n3              0.028436         0.011298         0.038608         0.016400   \n4              0.138822         0.041492         0.215029         0.062580   \n5              0.001063         0.000869         0.011373         0.007204   \n6              0.009311         0.005587         0.038714         0.018767   \n\n        feature_vicinity_0  feature_vicinity_1  feature_vicinity_2  \\\ncolumn                                                               \n3                 0.014218            0.006459            0.994945   \n4                 0.041162            0.033697            1.000000   \n5                 0.009564            0.002586            0.921216   \n6                 0.022346            0.003348            0.570548   \n\n        feature_vicinity_3  feature_vicinity_4  feature_vicinity_5  \\\ncolumn                                                               \n3                 0.000000            0.096367            0.142180   \n4                 0.530266            0.000000            0.460048   \n5                 0.085902            0.043571            0.000000   \n6                 0.478963            0.011173            0.421257   \n\n        feature_vicinity_6  feature_domain  \ncolumn                                      \n3                 0.470379        0.018201  \n4                 0.421308        0.058263  \n5                 0.306924        0.010157  \n6                 0.000000        0.005873  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_value_0</th>\n      <th>feature_value_1</th>\n      <th>feature_value_2</th>\n      <th>feature_value_3</th>\n      <th>feature_value_4</th>\n      <th>feature_value_5</th>\n      <th>feature_value_6</th>\n      <th>feature_value_7</th>\n      <th>feature_vicinity_0</th>\n      <th>feature_vicinity_1</th>\n      <th>feature_vicinity_2</th>\n      <th>feature_vicinity_3</th>\n      <th>feature_vicinity_4</th>\n      <th>feature_vicinity_5</th>\n      <th>feature_vicinity_6</th>\n      <th>feature_domain</th>\n    </tr>\n    <tr>\n      <th>column</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.006485</td>\n      <td>0.006485</td>\n      <td>0.028436</td>\n      <td>0.011298</td>\n      <td>0.038608</td>\n      <td>0.016400</td>\n      <td>0.014218</td>\n      <td>0.006459</td>\n      <td>0.994945</td>\n      <td>0.000000</td>\n      <td>0.096367</td>\n      <td>0.142180</td>\n      <td>0.470379</td>\n      <td>0.018201</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.005990</td>\n      <td>0.005990</td>\n      <td>0.138822</td>\n      <td>0.041492</td>\n      <td>0.215029</td>\n      <td>0.062580</td>\n      <td>0.041162</td>\n      <td>0.033697</td>\n      <td>1.000000</td>\n      <td>0.530266</td>\n      <td>0.000000</td>\n      <td>0.460048</td>\n      <td>0.421308</td>\n      <td>0.058263</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.001063</td>\n      <td>0.001063</td>\n      <td>0.004642</td>\n      <td>0.004642</td>\n      <td>0.001063</td>\n      <td>0.000869</td>\n      <td>0.011373</td>\n      <td>0.007204</td>\n      <td>0.009564</td>\n      <td>0.002586</td>\n      <td>0.921216</td>\n      <td>0.085902</td>\n      <td>0.043571</td>\n      <td>0.000000</td>\n      <td>0.306924</td>\n      <td>0.010157</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.003332</td>\n      <td>0.003332</td>\n      <td>0.009311</td>\n      <td>0.005587</td>\n      <td>0.038714</td>\n      <td>0.018767</td>\n      <td>0.022346</td>\n      <td>0.003348</td>\n      <td>0.570548</td>\n      <td>0.478963</td>\n      <td>0.011173</td>\n      <td>0.421257</td>\n      <td>0.000000</td>\n      <td>0.005873</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_features_df.iloc[:,[1] + list(range(5,correction_features_df.shape[1]))].groupby(\"column\").mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "correction_features_df[\"wrong_correction\"] = (correction_features_df[\"old_value\"] == correction_features_df[\"actual_value\"]) & (correction_features_df[\"old_value\"] != correction_features_df[\"new_value\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.044770206022187"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_features_df[\"wrong_correction\"].sum() / correction_features_df.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "[1390, 114, 308, 288, 514, 393, 525]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinct_features = []\n",
    "\n",
    "for column_index in range(d.dataframe.shape[1]):\n",
    "    unique_rows = np.unique(d.column_features[column_index], axis=0)\n",
    "    distinct_features.append(unique_rows.shape[0])\n",
    "\n",
    "distinct_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "cluster_features = []\n",
    "\n",
    "for cluster_i in range(1,21):\n",
    "    cluster_features.append(d.column_features[3][\n",
    "        [key[0] for key in d.clusters_k_j_c_ce[21][3][cluster_i].keys()]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "cluster_feature_means = np.array([cluster.mean(axis=0) for cluster in cluster_features])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "1      3\n2      2\n4      3\n7      1\n10     1\n12     2\n13     1\n31     1\n32     1\n72     1\n102    1\n211    1\n344    1\n751    1\n760    1\ndtype: int64"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Series([len(cluster) for cluster in d.clusters_k_j_c_ce[21][3].values()]).value_counts().sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "df = d.correction_prediction_dfs[0][5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "884"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prediction\"].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "cell\n(5, 5)       0\n(1987, 5)    0\n(903, 5)     0\n(1414, 5)    0\n(388, 5)     0\n(391, 5)     0\n(1967, 5)    0\n(1434, 5)    0\n(879, 5)     0\n(398, 5)     0\n(1439, 5)    0\n(1443, 5)    0\n(1960, 5)    0\n(1451, 5)    0\n(1469, 5)    0\n(870, 5)     0\n(1944, 5)    0\n(407, 5)     0\n(1927, 5)    0\n(1917, 5)    0\n(1911, 5)    0\n(1908, 5)    0\n(1879, 5)    0\n(1850, 5)    0\n(863, 5)     0\n(861, 5)     0\n(1990, 5)    0\n(851, 5)     0\n(374, 5)     0\n(2000, 5)    0\n            ..\n(796, 5)     1\n(763, 5)     1\n(765, 5)     1\n(767, 5)     1\n(768, 5)     1\n(769, 5)     1\n(771, 5)     1\n(772, 5)     1\n(774, 5)     1\n(775, 5)     1\n(776, 5)     1\n(778, 5)     1\n(780, 5)     1\n(781, 5)     1\n(782, 5)     1\n(783, 5)     1\n(784, 5)     1\n(785, 5)     1\n(786, 5)     1\n(787, 5)     1\n(788, 5)     1\n(789, 5)     1\n(790, 5)     1\n(791, 5)     1\n(792, 5)     1\n(793, 5)     1\n(794, 5)     1\n(795, 5)     1\n(761, 5)     1\n(2318, 5)    1\nName: prediction, Length: 1057, dtype: int64"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"prediction\"].groupby(df[\"cell\"]).sum().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df = df[df[\"prediction\"] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f4019e7de10>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAU70lEQVR4nO3dcZBdZ33e8e8TjCFhE0nYyY5HUpE7KKEuLsTeAWeYSXZRk7FNB7kpeMy4teRRq07HJSTQ1kr7B22nnZrpTF08ZeiomEZmEhbHCbFqmyQe4R2GTuxGwmAZuwThyFiLsMHIootLEtJf/7ivw1qsvFf33r3Lnv1+Zu7sOe9533ven1Z6dPbde89NVSFJ6pYfWe0JSJJGz3CXpA4y3CWpgwx3Seogw12SOui81Z4AwIUXXljbtm0baOx3vvMdXvWqV412Qj/krHl9sOb1YZiajxw58s2q+smljv1QhPu2bds4fPjwQGPn5uaYnp4e7YR+yFnz+mDN68MwNSd58mzHXJaRpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDvqheIeqJK2mbfvuHXjs8VveNsKZjI5X7pLUQYa7JHVQX+Ge5NeSfDHJo0k+nuSVSS5O8lCSY0k+keT81vcVbf9YO75tJQuQJP2gZcM9yWbgV4Cpqno98DLgOuADwK1V9VrgFLCnDdkDnGrtt7Z+kqQx6ndZ5jzgR5OcB/wYcBJ4K3BXO34AuKZt72z7tOM7kmQ005Uk9SNVtXyn5D3Avwf+L/CHwHuAB9vVOUm2Ap+qqtcneRS4sqpOtGNfAd5cVd884zn3AnsBJicnL5+dnR2ogIWFBSYmJgYau1ZZ8/pgzeNzdP70wGMv3bxhqHMPU/PMzMyRqppa6tiyL4VMsone1fjFwHPAbwNXDjSTRapqP7AfYGpqqga9Wb03918frHl9WK2adw/zUsjrp4c690rV3M+yzN8G/rSqvlFVfwH8LvAWYGNbpgHYAsy37XlgK0A7vgF4dqSzliS9pH7C/avAFUl+rK2d7wAeAx4A3tH67ALubtsH2z7t+Kern7UfSdLILBvuVfUQvV+Mfg442sbsB24G3pvkGHABcHsbcjtwQWt/L7BvBeYtSXoJfd1+oKreD7z/jOYngDct0fe7wDuHn5okaVC+Q1WSOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqoGXDPcnPJPn8ose3k/xqklcnuT/Jl9vXTa1/ktyW5FiSR5JctvJlSJIW6+dj9r5UVW+sqjcClwPPA5+k9/F5h6pqO3CI73+c3lXA9vbYC3x4JSYuSTq7c12W2QF8paqeBHYCB1r7AeCatr0TuKN6HgQ2JrloJLOVJPXlXMP9OuDjbXuyqk627a8Dk217M/DUojEnWpskaUxSVf11TM4Hvgb8zap6OslzVbVx0fFTVbUpyT3ALVX12dZ+CLi5qg6f8Xx76S3bMDk5efns7OxABSwsLDAxMTHQ2LXKmtcHax6fo/OnBx576eYNQ517mJpnZmaOVNXUUsfOO4fnuQr4XFU93fafTnJRVZ1syy7PtPZ5YOuicVta24tU1X5gP8DU1FRNT0+fw1S+b25ujkHHrlXWvD5Y8/js3nfvwGOPXz891LlXquZzWZZ5F99fkgE4COxq27uAuxe139BeNXMFcHrR8o0kaQz6unJP8irgF4F/vKj5FuDOJHuAJ4FrW/t9wNXAMXqvrLlxZLOVJPWlr3Cvqu8AF5zR9iy9V8+c2beAm0YyO0nSQHyHqiR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBfYV7ko1J7kryv5M8nuTnkrw6yf1Jvty+bmp9k+S2JMeSPJLkspUtQZJ0pn6v3D8I/H5VvQ54A/A4sA84VFXbgUNtH3ofpL29PfYCHx7pjCVJy1o23JNsAH4euB2gqv68qp4DdgIHWrcDwDVteydwR/U8CGxMctHIZy5JOqt+rtwvBr4B/PckDyf5SPvA7MmqOtn6fB2YbNubgacWjT/R2iRJY5Le51m/RIdkCngQeEtVPZTkg8C3gXdX1cZF/U5V1aYk9wC3VNVnW/sh4OaqOnzG8+6lt2zD5OTk5bOzswMVsLCwwMTExEBj1yprXh+seXyOzp8eeOylmzcMde5hap6ZmTlSVVNLHTuvj/EngBNV9VDbv4ve+vrTSS6qqpNt2eWZdnwe2Lpo/JbW9iJVtR/YDzA1NVXT09P91PID5ubmGHTsWmXN64M1j8/uffcOPPb49dNDnXulal52Waaqvg48leRnWtMO4DHgILCrte0C7m7bB4Eb2qtmrgBOL1q+kSSNQT9X7gDvBn4zyfnAE8CN9P5juDPJHuBJ4NrW9z7gauAY8HzrK0kao77Cvao+Dyy1rrNjib4F3DTkvCRJQ/AdqpLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4S1IH9RXuSY4nOZrk80kOt7ZXJ7k/yZfb102tPUluS3IsySNJLlvJAiRJP+hcrtxnquqNiz5pex9wqKq2A4faPsBVwPb22At8eFSTlST1Z5hlmZ3AgbZ9ALhmUfsd1fMgsDHJRUOcR5J0jvoN9wL+MMmRJHtb22RVnWzbXwcm2/Zm4KlFY0+0NknSmKT3edbLdEo2V9V8kp8C7gfeDRysqo2L+pyqqk1J7gFuqarPtvZDwM1VdfiM59xLb9mGycnJy2dnZwcqYGFhgYmJiYHGrlXWvD5Y8/gcnT898NhLN28Y6tzD1DwzM3Nk0VL5i5zXzxNU1Xz7+kySTwJvAp5OclFVnWzLLs+07vPA1kXDt7S2M59zP7AfYGpqqqanp/ss58Xm5uYYdOxaZc3rgzWPz+599w489vj100Ode6VqXnZZJsmrkvz4C9vALwGPAgeBXa3bLuDutn0QuKG9auYK4PSi5RtJ0hj0c+U+CXwyyQv9f6uqfj/JHwN3JtkDPAlc2/rfB1wNHAOeB24c+awlSS9p2XCvqieANyzR/iywY4n2Am4ayewkSQPxHaqS1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR1kuEtSB/Ud7kleluTh9gHYJLk4yUNJjiX5RJLzW/sr2v6xdnzbykxdknQ253Ll/h7g8UX7HwBurarXAqeAPa19D3Cqtd/a+kmSxqivcE+yBXgb8JG2H+CtwF2tywHgmra9s+3Tju9o/SVJY9Lvlft/Bv4F8P/a/gXAc1X1vbZ/AtjctjcDTwG046dbf0nSmCz7AdlJ/g7wTFUdSTI9qhMn2QvsBZicnGRubm6g51lYWBh47FplzeuDNY/P+y793vKdzmLY+a5UzcuGO/AW4O1JrgZeCfwE8EFgY5Lz2tX5FmC+9Z8HtgInkpwHbACePfNJq2o/sB9gamqqpqenBypgbm6OQceuVda8Pljz+Ozed+/AY49fPz3UuVeq5mWXZarq16tqS1VtA64DPl1V1wMPAO9o3XYBd7ftg22fdvzTVVUjnbUk6SUN8zr3m4H3JjlGb0399tZ+O3BBa38vsG+4KUqSzlU/yzJ/parmgLm2/QTwpiX6fBd45wjmJkkakO9QlaQOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDlo23JO8Msn/SvKFJF9M8m9a+8VJHkpyLMknkpzf2l/R9o+149tWtgRJ0pn6uXL/M+CtVfUG4I3AlUmuAD4A3FpVrwVOAXta/z3AqdZ+a+snSRqjZcO9ehba7svbo4C3Ane19gPANW17Z9unHd+RJCObsSRpWamq5TslLwOOAK8FPgT8R+DBdnVOkq3Ap6rq9UkeBa6sqhPt2FeAN1fVN894zr3AXoDJycnLZ2dnBypgYWGBiYmJgcauVda8Pljz+BydPz3w2Es3bxjq3MPUPDMzc6SqppY6dl4/T1BVfwm8MclG4JPA6waayYufcz+wH2Bqaqqmp6cHep65uTkGHbtWWfP6YM3js3vfvQOPPX799FDnXqmaz+nVMlX1HPAA8HPAxiQv/OewBZhv2/PAVoB2fAPw7EhmK0nqSz+vlvnJdsVOkh8FfhF4nF7Iv6N12wXc3bYPtn3a8U9XP2s/kqSR6WdZ5iLgQFt3/xHgzqq6J8ljwGySfwc8DNze+t8OfCzJMeBbwHUrMG9J0ktYNtyr6hHgZ5dofwJ40xLt3wXeOZLZSZIG4jtUJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA7q52P2tiZ5IMljSb6Y5D2t/dVJ7k/y5fZ1U2tPktuSHEvySJLLVroISdKL9XPl/j3gfVV1CXAFcFOSS4B9wKGq2g4cavsAVwHb22Mv8OGRz1qS9JKWDfeqOllVn2vb/4feh2NvBnYCB1q3A8A1bXsncEf1PAhsTHLRyGcuSTqrVFX/nZNtwGeA1wNfraqNrT3AqaramOQe4Jaq+mw7dgi4uaoOn/Fce+ld2TM5OXn57OzsQAUsLCwwMTEx0Ni1yprXB2sen6Pzpwcee+nmDUOde5iaZ2ZmjlTV1FLHlv2A7BckmQB+B/jVqvp2L897qqqS9P+/RG/MfmA/wNTUVE1PT5/L8L8yNzfHoGPXKmteH6x5fHbvu3fgscevnx7q3CtVc1+vlknycnrB/ptV9but+ekXllva12da+zywddHwLa1NkjQm/bxaJsDtwONV9Z8WHToI7Grbu4C7F7Xf0F41cwVwuqpOjnDOkqRl9LMs8xbgHwBHk3y+tf1L4BbgziR7gCeBa9ux+4CrgWPA88CNI52xJGlZy4Z7+8VoznJ4xxL9C7hpyHlJkobgO1QlqYMMd0nqIMNdkjrIcJekDjLcJamDDHdJ6iDDXZI6yHCXpA4y3CWpgwx3Seogw12SOshwl6QOMtwlqYMMd0nqIMNdkjrIcJekDurnY/Y+muSZJI8uant1kvuTfLl93dTak+S2JMeSPJLkspWcvCRpaf1cuf8GcOUZbfuAQ1W1HTjU9gGuAra3x17gw6OZpiTpXCwb7lX1GeBbZzTvBA607QPANYva76ieB4GNSS4a1WQlSf1J7yNPl+mUbAPuqarXt/3nqmpj2w5wqqo2JrkHuKV97ipJDgE3V9XhJZ5zL72reyYnJy+fnZ0dqICFhQUmJiYGGrtWWfP6YM3jc3T+9MBjL928YahzD1PzzMzMkaqaWurYsh+QvZyqqiTL/w/xg+P2A/sBpqamanp6eqDzz83NMejYtcqa1wdrHp/d++4deOzx66eHOvdK1Tzoq2WefmG5pX19prXPA1sX9dvS2iRJYzRouB8EdrXtXcDdi9pvaK+auQI4XVUnh5yjJOkcLbssk+TjwDRwYZITwPuBW4A7k+wBngSubd3vA64GjgHPAzeuwJwlSctYNtyr6l1nObRjib4F3DTspCRJw/EdqpLUQYa7JHWQ4S5JHWS4S1IHGe6S1EFDv0NVkkbl6Pzpgd8tevyWt414NmubV+6S1EGGuyR1kOEuSR1kuEtSBxnuktRBhrskdZDhLkkdZLhLUgcZ7pLUQYa7JHXQioR7kiuTfCnJsST7VuIckqSzG3m4J3kZ8CHgKuAS4F1JLhn1eSRJZ7cSV+5vAo5V1RNV9efALLBzBc4jSTqLlbgr5GbgqUX7J4A3n9kpyV5gb9tdSPKlAc93IfDNAceuVda8PljzOcgHRjyT8Z13mO/za852YNVu+VtV+4H9wz5PksNVNTWCKa0Z1rw+WPP6sFI1r8SyzDywddH+ltYmSRqTlQj3Pwa2J7k4yfnAdcDBFTiPJOksRr4sU1XfS/JPgT8AXgZ8tKq+OOrzLDL00s4aZM3rgzWvDytSc6pqJZ5XkrSKfIeqJHWQ4S5JHbRmwn25Wxok2Z3kG0k+3x7/cDXmOUr93MYhybVJHkvyxSS/Ne45jlof3+dbF32P/yTJc6sxz1Hqo+a/luSBJA8neSTJ1asxz1Hpo97XJDnUap1LsmU15jlKST6a5Jkkj57leJLc1v5MHkly2dAnraof+ge9X8x+BfjrwPnAF4BLzuizG/gvqz3XMde8HXgY2NT2f2q1573SNZ/R/930fmG/6nNf4e/zfuCftO1LgOOrPe8Vrve3gV1t+63Ax1Z73iOo++eBy4BHz3L8auBTQIArgIeGPedauXJfj7c06KfmfwR8qKpOAVTVM2Oe46id6/f5XcDHxzKzldNPzQX8RNveAHxtjPMbtX7qvQT4dNt+YInja05VfQb41kt02QncUT0PAhuTXDTMOddKuC91S4PNS/T7e+1HmruSbF3i+FrST80/Dfx0kv+Z5MEkV45tdiuj3+8zSV4DXMz3Q2Ct6qfmfw38/SQngPvo/cSyVvVT7xeAX27bfxf48SQXjGFuq6nvv/v9Wivh3o//AWyrqr8F3A8cWOX5jMN59JZmpuldxf63JBtXdUbjcx1wV1X95WpPZAzeBfxGVW2h9+P7x5J06d/umf4Z8AtJHgZ+gd473NfD93mk1spfkGVvaVBVz1bVn7XdjwCXj2luK6Wf2zicAA5W1V9U1Z8Cf0Iv7Neqc7l1xXWs/SUZ6K/mPcCdAFX1R8Ar6d1sai3q59/y16rql6vqZ4F/1drW/C/OlzHy27aslXBf9pYGZ6xPvR14fIzzWwn93Mbh9+hdtZPkQnrLNE+Mc5Ij1tetK5K8DtgE/NGY57cS+qn5q8AOgCR/g164f2Ossxydfv4tX7joJ5NfBz465jmuhoPADe1VM1cAp6vq5DBPuGp3hTwXdZZbGiT5t8DhqjoI/EqStwPfo/eLi92rNuER6LPmPwB+Kclj9H5s/edV9ezqzXo4fdYMvUCYrfYyg7Wsz5rfR2/J7dfo/XJ191qtvc96p4H/kKSAzwA3rdqERyTJx+nVdWH73cn7gZcDVNV/pfe7lKuBY8DzwI1Dn3ON/h2RJL2EtbIsI0k6B4a7JHWQ4S5JHWS4S1IHGe6S1EGGuyR1kOEuSR30/wEc0txQIiCpMwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"probability\"].hist(bins=np.linspace(0.5, 1.0, 21))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [prediction, cell, probability, correction]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>cell</th>\n      <th>probability</th>\n      <th>correction</th>\n    </tr>\n    <tr>\n      <th>cell</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated = df.groupby(\"cell\").agg({\"prediction\": \"sum\",\n",
    "                                     \"cell\": \"first\",\n",
    "                                     \"probability\": list,\n",
    "                                     \"correction\": list})\n",
    "aggregated = aggregated[aggregated[\"prediction\"] == 2]\n",
    "aggregated"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare correction and actual\n",
    "cell = (59,5)\n",
    "print(d.corrected_cells[cell])\n",
    "print(actual_errors[cell])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "           cell  confidence  detection_correct  correct\n0      (222, 3)    1.000000               True     True\n1      (572, 3)    1.000000               True     True\n2      (688, 3)    1.000000               True     True\n3     (1042, 3)    1.000000               True     True\n4     (1099, 3)    1.000000               True     True\n5     (1409, 3)    1.000000               True     True\n6     (1498, 3)    1.000000               True     True\n7     (2016, 3)    1.000000               True     True\n8     (2152, 3)    1.000000               True     True\n9       (54, 3)    1.000000               True     True\n10      (55, 3)    1.000000               True     True\n11      (56, 3)    1.000000               True     True\n12      (58, 3)    1.000000               True     True\n13      (60, 3)    1.000000               True     True\n14      (67, 3)    1.000000               True     True\n15      (69, 3)    1.000000               True     True\n16      (73, 3)    1.000000               True     True\n17      (82, 3)    1.000000               True     True\n18      (84, 3)    1.000000               True     True\n19      (85, 3)    1.000000               True    False\n20      (88, 3)    1.000000              False    False\n21      (90, 3)    1.000000               True     True\n22      (92, 3)    1.000000               True     True\n23      (94, 3)    1.000000               True     True\n24      (97, 3)    1.000000               True     True\n25     (101, 3)    1.000000               True     True\n26     (102, 3)    1.000000               True     True\n27     (104, 3)    1.000000               True     True\n28     (109, 3)    1.000000               True     True\n29     (110, 3)    1.000000               True     True\n...         ...         ...                ...      ...\n2494  (1920, 6)    0.999995               True     True\n2495  (2012, 6)    0.917713               True     True\n2496  (2112, 6)    0.917713               True     True\n2497  (2217, 6)    0.917713               True     True\n2498  (2357, 6)    0.999995               True     True\n2499    (17, 4)    1.000000              False    False\n2500   (102, 4)    1.000000              False    False\n2501   (282, 4)    1.000000               True     True\n2502   (389, 4)    1.000000              False    False\n2503   (528, 4)    1.000000               True     True\n2504   (588, 4)    1.000000              False    False\n2505   (720, 4)    1.000000               True     True\n2506   (765, 4)    1.000000               True     True\n2507   (796, 4)    1.000000               True     True\n2508   (902, 4)    1.000000              False    False\n2509   (973, 4)    1.000000              False    False\n2510  (1019, 4)    1.000000               True     True\n2511  (1161, 4)    1.000000               True     True\n2512  (1275, 4)    1.000000              False    False\n2513  (1413, 4)    1.000000               True     True\n2514  (1539, 4)    1.000000              False    False\n2515  (1613, 4)    1.000000               True     True\n2516  (1686, 4)    1.000000              False    False\n2517  (1849, 4)    1.000000              False    False\n2518  (1909, 4)    1.000000              False    False\n2519  (2041, 4)    1.000000               True     True\n2520  (2141, 4)    1.000000              False    False\n2521  (2246, 4)    1.000000               True     True\n2522  (2280, 4)    1.000000              False    False\n2523  (2343, 4)    1.000000              False    False\n\n[2524 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell</th>\n      <th>confidence</th>\n      <th>detection_correct</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(222, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(572, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(688, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1042, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(1099, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(1409, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(1498, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(2016, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(2152, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(54, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(55, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(56, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(58, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(60, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(67, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(69, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(73, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(82, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(84, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(85, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>(88, 3)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>(90, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>(92, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>(94, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>(97, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>(101, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>(102, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>(104, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>(109, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>(110, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2494</th>\n      <td>(1920, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2495</th>\n      <td>(2012, 6)</td>\n      <td>0.917713</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2496</th>\n      <td>(2112, 6)</td>\n      <td>0.917713</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2497</th>\n      <td>(2217, 6)</td>\n      <td>0.917713</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2498</th>\n      <td>(2357, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2499</th>\n      <td>(17, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2500</th>\n      <td>(102, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2501</th>\n      <td>(282, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2502</th>\n      <td>(389, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2503</th>\n      <td>(528, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2504</th>\n      <td>(588, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2505</th>\n      <td>(720, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2506</th>\n      <td>(765, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2507</th>\n      <td>(796, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2508</th>\n      <td>(902, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2509</th>\n      <td>(973, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2510</th>\n      <td>(1019, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2511</th>\n      <td>(1161, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2512</th>\n      <td>(1275, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2513</th>\n      <td>(1413, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2514</th>\n      <td>(1539, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2515</th>\n      <td>(1613, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2516</th>\n      <td>(1686, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2517</th>\n      <td>(1849, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2518</th>\n      <td>(1909, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2519</th>\n      <td>(2041, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2520</th>\n      <td>(2141, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2521</th>\n      <td>(2246, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2522</th>\n      <td>(2280, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2523</th>\n      <td>(2343, 4)</td>\n      <td>1.000000</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>2524 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_list = list(d.correction_confidences.items())\n",
    "is_correctly_detected = [cell_conf_tuple[0] in actual_errors for cell_conf_tuple in confidence_list]\n",
    "is_correctly_corrected = [cell_conf_tuple[0] in actual_errors and\n",
    "                          d.corrected_cells[cell_conf_tuple[0]] == actual_errors[cell_conf_tuple[0]]\n",
    "                          for cell_conf_tuple in confidence_list]\n",
    "correction_confidence_df = DataFrame({\"cell\": [item[0] for item in confidence_list],\n",
    "                                      \"confidence\": [item[1] for item in confidence_list],\n",
    "                                      \"detection_correct\": is_correctly_detected,\n",
    "                                      \"correct\": is_correctly_corrected})\n",
    "correction_confidence_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "           cell  confidence  detection_correct  correct\n19      (85, 3)    1.000000               True    False\n58     (188, 3)    1.000000               True    False\n84     (372, 3)    1.000000               True    False\n123    (475, 3)    1.000000               True    False\n152    (667, 3)    1.000000               True    False\n175    (753, 3)    1.000000               True    False\n212    (849, 3)    1.000000               True    False\n241   (1041, 3)    1.000000               True    False\n255   (1108, 3)    1.000000               True    False\n291   (1258, 3)    1.000000               True    False\n347   (1485, 3)    1.000000               True    False\n358   (1522, 3)    1.000000               True    False\n394   (1622, 3)    1.000000               True    False\n418   (1796, 3)    1.000000               True    False\n447   (1988, 3)    1.000000               True    False\n473   (2088, 3)    1.000000               True    False\n500   (2193, 3)    1.000000               True    False\n537     (53, 4)    1.000000               True    False\n540     (91, 4)    1.000000               True    False\n541    (129, 4)    1.000000               True    False\n552    (340, 4)    1.000000               True    False\n555    (378, 4)    1.000000               True    False\n556    (416, 4)    1.000000               True    False\n570    (732, 4)    1.000000               True    False\n582    (991, 4)    1.000000               True    False\n594   (1226, 4)    1.000000               True    False\n597   (1264, 4)    1.000000               True    False\n598   (1302, 4)    1.000000               True    False\n600   (1326, 4)    1.000000               True    False\n604   (1399, 4)    1.000000               True    False\n...         ...         ...                ...      ...\n2263  (1459, 6)    0.999995               True    False\n2264  (1464, 6)    0.999995               True    False\n2265  (1479, 6)    0.999995               True    False\n2266  (1533, 6)    0.999995               True    False\n2267  (1587, 6)    0.999995               True    False\n2269  (1617, 6)    0.999995               True    False\n2271  (1744, 6)    0.999995               True    False\n2272  (1763, 6)    0.999995               True    False\n2274  (1803, 6)    0.999995               True    False\n2276  (1819, 6)    0.999995               True    False\n2277  (1863, 6)    0.999995               True    False\n2279  (1903, 6)    0.999995               True    False\n2281  (1919, 6)    0.999995               True    False\n2282  (1955, 6)    0.999995               True    False\n2284  (1995, 6)    0.999995               True    False\n2286  (2011, 6)    0.999995               True    False\n2287  (2055, 6)    0.999995               True    False\n2289  (2095, 6)    0.999995               True    False\n2291  (2111, 6)    0.999995               True    False\n2292  (2160, 6)    0.999995               True    False\n2294  (2200, 6)    0.999995               True    False\n2296  (2216, 6)    0.999995               True    False\n2297  (2324, 6)    0.999995               True    False\n2298  (2326, 6)    0.999995               True    False\n2301  (2356, 6)    0.999995               True    False\n2343   (292, 6)    0.999995               True    False\n2350   (970, 6)    0.999995               True    False\n2354  (1638, 6)    0.999995               True    False\n2355  (1697, 6)    0.999995               True    False\n2363  (2291, 6)    0.999995               True    False\n\n[194 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell</th>\n      <th>confidence</th>\n      <th>detection_correct</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19</th>\n      <td>(85, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>(188, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>84</th>\n      <td>(372, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>(475, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>(667, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>175</th>\n      <td>(753, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>212</th>\n      <td>(849, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>241</th>\n      <td>(1041, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>(1108, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>291</th>\n      <td>(1258, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>(1485, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>(1522, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>(1622, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>418</th>\n      <td>(1796, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>(1988, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>473</th>\n      <td>(2088, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>(2193, 3)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>537</th>\n      <td>(53, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>540</th>\n      <td>(91, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>541</th>\n      <td>(129, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>(340, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>(378, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>556</th>\n      <td>(416, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>570</th>\n      <td>(732, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>582</th>\n      <td>(991, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>594</th>\n      <td>(1226, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>597</th>\n      <td>(1264, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>598</th>\n      <td>(1302, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>600</th>\n      <td>(1326, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>604</th>\n      <td>(1399, 4)</td>\n      <td>1.000000</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2263</th>\n      <td>(1459, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2264</th>\n      <td>(1464, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2265</th>\n      <td>(1479, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2266</th>\n      <td>(1533, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2267</th>\n      <td>(1587, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2269</th>\n      <td>(1617, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2271</th>\n      <td>(1744, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2272</th>\n      <td>(1763, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2274</th>\n      <td>(1803, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2276</th>\n      <td>(1819, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2277</th>\n      <td>(1863, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2279</th>\n      <td>(1903, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2281</th>\n      <td>(1919, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2282</th>\n      <td>(1955, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2284</th>\n      <td>(1995, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2286</th>\n      <td>(2011, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2287</th>\n      <td>(2055, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2289</th>\n      <td>(2095, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2291</th>\n      <td>(2111, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2292</th>\n      <td>(2160, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2294</th>\n      <td>(2200, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2296</th>\n      <td>(2216, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2297</th>\n      <td>(2324, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2298</th>\n      <td>(2326, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2301</th>\n      <td>(2356, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2343</th>\n      <td>(292, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2350</th>\n      <td>(970, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2354</th>\n      <td>(1638, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2355</th>\n      <td>(1697, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>(2291, 6)</td>\n      <td>0.999995</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>194 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction_confidence_df[correction_confidence_df[\"detection_correct\"] & ~correction_confidence_df[\"correct\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "            cell  correction  prediction  probability\n1419     (54, 3)   8:41 a.m.           1          1.0\n1463     (55, 3)   7:45 p.m.           1          1.0\n1507     (56, 3)   3:27 p.m.           1          1.0\n1540     (58, 3)  11:25 a.m.           1          1.0\n1639     (60, 3)  11:25 p.m.           1          1.0\n1859     (67, 3)   8:15 a.m.           1          1.0\n1947     (69, 3)   4:15 p.m.           1          1.0\n2122     (73, 3)   2:55 p.m.           1          1.0\n2519     (82, 3)   7:53 a.m.           1          1.0\n2607     (84, 3)  11:45 a.m.           1          1.0\n2651     (85, 3)   2:46 p.m.           1          1.0\n2739     (88, 3)   7:27 p.m.           1          1.0\n2827     (90, 3)  12:57 p.m.           1          1.0\n2871     (92, 3)   7:15 a.m.           1          1.0\n2959     (94, 3)   6:45 p.m.           1          1.0\n3047     (97, 3)   1:55 p.m.           1          1.0\n3179    (101, 3)   4:55 p.m.           1          1.0\n3223    (102, 3)   7:25 a.m.           1          1.0\n3311    (104, 3)   4:16 p.m.           1          1.0\n3531    (109, 3)   1:33 p.m.           1          1.0\n3575    (110, 3)  12:15 p.m.           1          1.0\n3619    (112, 3)  11:55 p.m.           1          1.0\n3663    (113, 3)   4:25 p.m.           1          1.0\n3751    (115, 3)   8:25 p.m.           1          1.0\n3795    (116, 3)   6:59 a.m.           1          1.0\n3839    (117, 3)   8:35 a.m.           1          1.0\n3883    (118, 3)   8:29 a.m.           1          1.0\n3961    (121, 3)   7:35 a.m.           1          1.0\n4103    (124, 3)   1:45 p.m.           1          1.0\n4147    (125, 3)  11:15 a.m.           1          1.0\n...          ...         ...         ...          ...\n68436  (2142, 3)   2:55 p.m.           1          1.0\n68970  (2159, 3)   8:41 a.m.           1          1.0\n69058  (2163, 3)  11:25 a.m.           1          1.0\n69278  (2169, 3)   7:35 a.m.           1          1.0\n69322  (2170, 3)   9:45 a.m.           1          1.0\n69410  (2172, 3)   8:15 a.m.           1          1.0\n69624  (2178, 3)   2:55 p.m.           1          1.0\n70026  (2187, 3)   7:53 a.m.           1          1.0\n70114  (2189, 3)  11:45 a.m.           1          1.0\n70158  (2190, 3)   2:46 p.m.           1          1.0\n70246  (2192, 3)   5:25 p.m.           1          1.0\n70290  (2193, 3)   7:27 p.m.           1          1.0\n70378  (2195, 3)  12:57 p.m.           1          1.0\n70422  (2196, 3)   3:35 p.m.           1          1.0\n70510  (2201, 3)   1:55 p.m.           1          1.0\n70642  (2205, 3)   4:55 p.m.           1          1.0\n70730  (2207, 3)   4:16 p.m.           1          1.0\n70950  (2214, 3)   1:29 p.m.           1          1.0\n71038  (2221, 3)   8:29 a.m.           1          1.0\n71126  (2223, 3)   2:53 p.m.           1          1.0\n71170  (2224, 3)   7:35 a.m.           1          1.0\n71302  (2227, 3)   1:45 p.m.           1          1.0\n71346  (2228, 3)  11:15 a.m.           1          1.0\n71428  (2230, 3)   2:55 p.m.           1          1.0\n71522  (2232, 3)   8:55 a.m.           1          1.0\n71690  (2240, 3)   8:35 a.m.           1          1.0\n71830  (2243, 3)  11:25 a.m.           1          1.0\n71912  (2247, 3)   2:55 p.m.           1          1.0\n72803  (2277, 3)   2:46 p.m.           1          1.0\n74778  (2361, 3)   2:46 p.m.           1          1.0\n\n[510 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cell</th>\n      <th>correction</th>\n      <th>prediction</th>\n      <th>probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1419</th>\n      <td>(54, 3)</td>\n      <td>8:41 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1463</th>\n      <td>(55, 3)</td>\n      <td>7:45 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1507</th>\n      <td>(56, 3)</td>\n      <td>3:27 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1540</th>\n      <td>(58, 3)</td>\n      <td>11:25 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1639</th>\n      <td>(60, 3)</td>\n      <td>11:25 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1859</th>\n      <td>(67, 3)</td>\n      <td>8:15 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1947</th>\n      <td>(69, 3)</td>\n      <td>4:15 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2122</th>\n      <td>(73, 3)</td>\n      <td>2:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2519</th>\n      <td>(82, 3)</td>\n      <td>7:53 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2607</th>\n      <td>(84, 3)</td>\n      <td>11:45 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2651</th>\n      <td>(85, 3)</td>\n      <td>2:46 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2739</th>\n      <td>(88, 3)</td>\n      <td>7:27 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2827</th>\n      <td>(90, 3)</td>\n      <td>12:57 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2871</th>\n      <td>(92, 3)</td>\n      <td>7:15 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2959</th>\n      <td>(94, 3)</td>\n      <td>6:45 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3047</th>\n      <td>(97, 3)</td>\n      <td>1:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3179</th>\n      <td>(101, 3)</td>\n      <td>4:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3223</th>\n      <td>(102, 3)</td>\n      <td>7:25 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3311</th>\n      <td>(104, 3)</td>\n      <td>4:16 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3531</th>\n      <td>(109, 3)</td>\n      <td>1:33 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3575</th>\n      <td>(110, 3)</td>\n      <td>12:15 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3619</th>\n      <td>(112, 3)</td>\n      <td>11:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3663</th>\n      <td>(113, 3)</td>\n      <td>4:25 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3751</th>\n      <td>(115, 3)</td>\n      <td>8:25 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3795</th>\n      <td>(116, 3)</td>\n      <td>6:59 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3839</th>\n      <td>(117, 3)</td>\n      <td>8:35 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3883</th>\n      <td>(118, 3)</td>\n      <td>8:29 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3961</th>\n      <td>(121, 3)</td>\n      <td>7:35 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4103</th>\n      <td>(124, 3)</td>\n      <td>1:45 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4147</th>\n      <td>(125, 3)</td>\n      <td>11:15 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>68436</th>\n      <td>(2142, 3)</td>\n      <td>2:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>68970</th>\n      <td>(2159, 3)</td>\n      <td>8:41 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>69058</th>\n      <td>(2163, 3)</td>\n      <td>11:25 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>69278</th>\n      <td>(2169, 3)</td>\n      <td>7:35 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>69322</th>\n      <td>(2170, 3)</td>\n      <td>9:45 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>69410</th>\n      <td>(2172, 3)</td>\n      <td>8:15 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>69624</th>\n      <td>(2178, 3)</td>\n      <td>2:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70026</th>\n      <td>(2187, 3)</td>\n      <td>7:53 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70114</th>\n      <td>(2189, 3)</td>\n      <td>11:45 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70158</th>\n      <td>(2190, 3)</td>\n      <td>2:46 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70246</th>\n      <td>(2192, 3)</td>\n      <td>5:25 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70290</th>\n      <td>(2193, 3)</td>\n      <td>7:27 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70378</th>\n      <td>(2195, 3)</td>\n      <td>12:57 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70422</th>\n      <td>(2196, 3)</td>\n      <td>3:35 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70510</th>\n      <td>(2201, 3)</td>\n      <td>1:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70642</th>\n      <td>(2205, 3)</td>\n      <td>4:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70730</th>\n      <td>(2207, 3)</td>\n      <td>4:16 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>70950</th>\n      <td>(2214, 3)</td>\n      <td>1:29 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71038</th>\n      <td>(2221, 3)</td>\n      <td>8:29 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71126</th>\n      <td>(2223, 3)</td>\n      <td>2:53 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71170</th>\n      <td>(2224, 3)</td>\n      <td>7:35 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71302</th>\n      <td>(2227, 3)</td>\n      <td>1:45 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71346</th>\n      <td>(2228, 3)</td>\n      <td>11:15 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71428</th>\n      <td>(2230, 3)</td>\n      <td>2:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71522</th>\n      <td>(2232, 3)</td>\n      <td>8:55 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71690</th>\n      <td>(2240, 3)</td>\n      <td>8:35 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71830</th>\n      <td>(2243, 3)</td>\n      <td>11:25 a.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>71912</th>\n      <td>(2247, 3)</td>\n      <td>2:55 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>72803</th>\n      <td>(2277, 3)</td>\n      <td>2:46 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>74778</th>\n      <td>(2361, 3)</td>\n      <td>2:46 p.m.</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>510 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.correction_prediction_dfs[0][3][d.correction_prediction_dfs[0][3][\"prediction\"] == 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f401a83ac90>"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = d.correction_prediction_dfs[15][3]\n",
    "df[\"probability\"].hist(bins=np.linspace(0.0, 1.0, 21))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}